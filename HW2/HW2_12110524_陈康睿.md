# CS405 Homework #2

**SID**: 12110524

**Name**: 陈康睿



## Question 1

1. True (Ref: PRML 2.3.1, 2.3.2)

   $$
   \begin{aligned}
       p(\bold{x_a | x_b}) &= \cal{N}\bold{(x_a | \mu_a - \Sigma_{ab}\Sigma_{bb}^{-1}(x_b - \mu_b), \Sigma_{aa} - \Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba})}\\
       &= \cal{N}\bold{(x_a | \mu_a - \Lambda_{ab}^{-1}\Lambda_{bb}(x_b - \mu_b), \Lambda_{aa}^{-1})}\\
   	p(\bold{x_a}) &= \cal{N}\bold{(x_a | \mu_a, \Sigma_{aa})}
   \end{aligned}
   $$



2. Merge $x_a$, $x_b$, then 

   $$
   x = 
   \begin{bmatrix}
       x_{a, b}\\
       x_c\\
   \end{bmatrix}
   &
   
   \mu = 
   \begin{bmatrix}
       \mu_{a, b}\\
       \mu_c\\
   \end{bmatrix}
   &
   
   \Sigma = 
   \begin{bmatrix}
       \Sigma_{(a, b)(a, b)} & \Sigma_{(a, b)c}\\
       \Sigma_{c(a, b)} & \Sigma_{cc}\\
   \end{bmatrix}
   $$

   Then we can take advantage of the marginal result in (1):
   $$
   p(x_{a, b}) = \cal{N}\bold(x_{a, b} | \mu_{a, b}, \Sigma_{(a, b)(a, b)})
   $$
   Now we do the partition again:
   $$
   x_{a, b} =
   \begin{bmatrix}
       x_a\\
       x_b\\
   \end{bmatrix}
   &
   
   \mu_{a, b} = 
   \begin{bmatrix}
       \mu_a\\
       \mu_b\\
   \end{bmatrix}
   &
   
   \Sigma_{a, b} = 
   \begin{bmatrix}
       \Sigma_{aa} & \Sigma_{ab}\\
       \Sigma_{ba} & \Sigma_{bb}\\
   \end{bmatrix}
   $$
   Finally we use the conditional result in (1):
   $$
   p(\bold{x_a | x_b}) = \cal{N}\bold{(x_a | \mu_a - \Lambda_{ab}^{-1}\Lambda_{bb}(x_b - \mu_b), \Lambda_{aa}^{-1})}
   $$




## Question 2

1. Using the marginal result in Q1.1:
   $$
   p(x) = \cal{N}(x | \mu_x, \Sigma_{xx}) = \cal{N}(x | \mu, \Lambda^{-1})
   $$

2. Using the conditional result in Q1.1:
   $$
   \begin{aligned}
   p(\bold{y | x}) &= \cal{N}\bold{(y | \mu_y - \Sigma_{yx}\Sigma_{xx}^{-1}(x - \mu_x), \Sigma_{yy} - \Sigma_{yx}\Sigma_{xx}^{-1}\Sigma_{xy})}\\
   		 &= \cal{N}\bold{(y | A\mu + b - A\Lambda^{-1}\Lambda(x - \mu), L^{-1} + A\Lambda^{-1}A^T - A\Lambda^{-1}\Lambda\Lambda^{-1}A^T)}\\
   		 &= \cal{N}\bold{(y | Ax + b, L^{-1})}
   \end{aligned}
   $$
   



## Question 3

Log likelihood function respect to $\Sigma$:
$$
\begin{aligned}
	\frac{\part \ln p(\bold{X} | \mu, \Sigma)}{\part \Sigma} &= - \frac{\part}{\part \Sigma}\left(\frac{N}{2}\ln|\Sigma| + \frac{1}{2}\sum_{n = 1}^{N}(\bold{x}_n-\mu)^T \Sigma^{-1} (\bold{x}_n - \mu)\right)\\
	&= \frac{1}{2}\Sigma^{-1}\sum_{n = 1}^{N} (\bold{x}_n - \mu)(\bold{x}_n - \mu)^{T}\Sigma^{-1} - \frac{N}{2}\Sigma^{-1} & (with\ \Sigma^{-T} = \Sigma^{-1})\\
	&= 0
\end{aligned}
$$
Then we can get:
$$
\Sigma_{ML} = \sum_{n = 1}^{N} (\bold{x}_n - \mu)(\bold{x}_n - \mu)^{T}
$$
Obviously, $\Sigma_{ML}$ is symmetric, and $x^{T}\Sigma_{ML}x = \frac{1}{N}\sum_{n = 1}^{N}(x^T(\bold{x}_n - \mu)) ^ 2 > 0$ for any $x \ne 0, \exist \bold{x}_n \ne \mu$.

So the final result is symmetric and positive definite. 



## Question 4

Robbins-Monro sequential estimation formula:
$$
\theta^{(N)} = \theta^{(N−1)} + a_{N−1} \frac{\part}{\part\theta^{N−1}} \ln p(x_N |\theta^{N−1})
$$

1. Dissecting out the contribution from the final data point, we obtain:
   $$
   (\sigma_{ML}^2)^{(N)} = (\sigma_{ML}^2)^{(N-1)} + \frac{1}{N}\left((x_N - \mu_{ML})^2 - (\sigma_{ML}^2)^{(N-1)}\right)
   $$

   By likelihood:
   $$
   \lim_{N\rightarrow\infty}\frac{1}{N}\sum_{n = 1}^N \ln p(x_n | \mu, \sigma^2) = \mathbb{E}_x\left[\frac{\part}{\part\sigma^2} \ln p(x_n | \mu, \sigma^2)\right]
   $$
   Substituting into thesequential formula:
   $$
   (\sigma_{ML}^2)^{(N)} = (\sigma_{ML}^2)^{(N-1)} + a_{N - 1}\left(\frac{(x_N - \mu_{ML}^N)^2}{2(\sigma_{ML}^2)^{(N - 1)}} - \frac{1}{2(\sigma_{ML}^2)^{(N-1)}}\right)
   $$
   So $a_{N} = \frac{2}{N+1}(\sigma_{ML}^4)^{(N)}$

2. Similarly, dissecting out the last data point:
   $$
   \Sigma_{ML}^{(N)} = \Sigma_{ML}^{(N - 1)} + \frac{1}{N}\left((\bold{x}_N - \mu_{ML})(\bold{x}_N - \mu_{ML})^T - \Sigma_{ML}^{(N-1)}\right)
   $$
   By substitution:
   $$
   \Sigma_{ML}^{(N)} = \Sigma_{ML}^{(N - 1)} + \frac{a_{N-1}}{2}\left((\Sigma_{ML}^{-1})^{(N-1)} (\bold{x}_N - \mu_{ML}) (\bold{x}_N - \mu_{ML})^T (\Sigma_{ML}^{-1})^{(N-1)} - (\Sigma_{ML}^{-1})^{(N-1)}\right)
   $$
   Hence $a_{N} = \frac{2}{N+1}(\Sigma_{ML}^2)^{(N)}$



## Question 5

$\bold{Posterior} \propto \bold{Prior} \times \bold{Likelihood}$:
$$
\begin{aligned}
	p(\mu | \bold{X}) &\propto p(\mu)\prod_{n = 1}^{N}p(\bold{X}_n | \mu, \Sigma)\\
	&\propto \exp\left\{-\frac{1}{2}(\mu - \mu_0)^\bold{T}\Sigma_0^{-1}(\mu - \mu_0)-\frac{1}{2}\sum_{n = 1}^{N}(\bold{x}_n - \mu)^\bold{T}(\bold{x}_n - \mu)\right\}
\end{aligned}
$$
And the exponential terms can be rearranged by the power of $\mu$ (as we are finding the distribution of $\mu$, and the constant term can be seen as coefficient of $\exp$):
$$
-\frac{1}{2}\mu^\bold{T}(\Sigma_0^{-1} + N\Sigma^{-1})\mu + \mu^\bold{T}\left(\Sigma_0^{-1}\mu_0 + \Sigma^{-1}\sum_{n = 1}^N\bold{x}_n\right) + C
$$
where $C$ stands for constant.

As the exponent of $\cal{N}(\bold{x} | \mu, \Sigma)$ can be expressed by:
$$
-\frac{1}{2}\bold{x}^\bold{T}\Sigma^{-1}\bold{x} + \bold{x}^\bold{T}\Sigma^{-1}\mu + C
$$
So we can get:
$$
\begin{aligned}
	\mu_{post} &= (\Sigma_0^{-1} + N\Sigma^{-1})^{-1}\left(\Sigma_0^{-1}\mu_0 + \Sigma^{-1}\sum_{n = 1}^N\bold{x}_n\right)\\
	\Sigma_{post} &= (\Sigma_0^{-1} + N\Sigma^{-1})^{-1}
\end{aligned}
$$
Thus, $p(\mu | \bold{X}) = \cal{N}(\bold{x} | \mu_{post}, \Sigma_{post})$
